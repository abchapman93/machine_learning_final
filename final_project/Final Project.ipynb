{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Mar 30 12:00:24 2017\n",
    "\n",
    "@author: alec\n",
    "\"\"\"\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import sqlite3 as sqlite\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn= sqlite.connect(os.path.join(os.path.expanduser('~'),'Box Sync',\n",
    "'Radiology Annotation','Reference Standard','radiology_reports.sqlite'))\n",
    "cursor=conn.cursor()\n",
    "\n",
    "#ngram_vectorizer = CountVectorizer(ngram_range=(1,2), token_pattern=r'(?u)\\b\\w\\w+\\b', stop_words=\"english\",  min_df=2)\n",
    "\n",
    "#column names\n",
    "#(0, 'rowid', 'int', 0, None, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_notes = pd.read_sql(\"\"\"SELECT * FROM training_notes\"\"\",conn)\n",
    "#training_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_names = training_notes['name']\n",
    "training_text = training_notes['text']\n",
    "training_labels = training_notes['doc_class']\n",
    "training_content = zip(training_names,training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_text = {x[0]:x[1] for x in zip(training_names,training_text)}\n",
    "train_labels = {x[0]:x[1] for x in zip(training_names,training_labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stoplist = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training\n",
    "documents = [x.lower().strip() for x in training_text]\n",
    "documents = [re.sub(\"[^a-zA-Z?]\", ' ', x).split() for x in documents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = [[word for word in document if word not in stoplist]\n",
    "        for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "texts = [[token for token in text if frequency[token] > 1] for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with sklearn\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",tokenizer=None,preprocessor=None,stop_words=None,max_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [' '.join(x) for x in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_features = vectorizer.fit_transform(texts).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaa', 'abcess', 'abd', 'abdm', 'abdomen', 'abdomenal', 'abdominal', 'abdominis', 'abdominopelvic', 'aberrant', 'ablation', 'able', 'abn', 'abnomality', 'abnormal', 'abnormalities', 'abnormality', 'abnormally', 'abo', 'aborted']\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "print(vocab[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 aaa\n",
      "7 aeration\n",
      "51 ap\n",
      "5 attenuating\n",
      "2 breasts\n",
      "2 centimeter\n",
      "272 collections\n",
      "2 cont\n",
      "5 cutoff\n",
      "8 details\n",
      "2 double\n",
      "3 endocarditis\n",
      "59 excrete\n",
      "7 fibroids\n",
      "38 gallstones\n",
      "11 heavily\n",
      "86 hyperdense\n",
      "24 indeterminate\n",
      "3 intrab\n",
      "4 laparotomies\n",
      "55 located\n",
      "20 median\n",
      "11 musculature\n",
      "2 obliterated\n",
      "45 overall\n",
      "3 perfed\n",
      "32 pm\n",
      "12 presumed\n",
      "4 questioned\n",
      "9 reidentified\n",
      "51 rising\n",
      "2 sepsispo\n",
      "39 smv\n",
      "2 striking\n",
      "2 sz\n",
      "80 tissues\n",
      "4 typical\n",
      "220 venous\n",
      "2 wvomiting\n"
     ]
    }
   ],
   "source": [
    "#Sum up the counts of each vocabulary word\n",
    "dist = np.sum(train_data_features,axis=0)\n",
    "for tag, count in zip(vocab[::100], dist[::100]):\n",
    "    print(count, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "forest = forest.fit(train_data_features, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testing set\n",
    "testing_notes = pd.read_sql(\"\"\"SELECT * FROM testing_notes\"\"\",conn)\n",
    "testing_names = testing_notes['name']\n",
    "testing_text = testing_notes['text']\n",
    "testing_labels = testing_notes['doc_class']\n",
    "testing_content = zip(testing_names,testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_documents = [x.lower().strip() for x in testing_text]\n",
    "test_documents = [re.sub(\"[^a-zA-Z?]\", ' ', x).split() for x in test_documents]\n",
    "testing_text = [[word for word in document if word not in stoplist]\n",
    "        for document in test_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_frequency = defaultdict(int)\n",
    "for text in testing_text:\n",
    "    for token in text:\n",
    "        test_frequency[token] += 1\n",
    "        \n",
    "testing_text = [[token for token in text if test_frequency[token] > 1] for text in testing_text]\n",
    "testing_text = [' '.join(x) for x in testing_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_features = vectorizer.transform(testing_text)\n",
    "test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = forest.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data={\"file name\":testing_names,\"prediction\":result,\"label\":testing_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "correct = 0\n",
    "incorrect = []\n",
    "for i in range(100):\n",
    "    if output['prediction'][i] == output['label'][i]:\n",
    "        correct += 1\n",
    "        counter += 1\n",
    "    else:\n",
    "        incorrect.append(output['file name'][i])\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = correct/counter\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_data_features, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = mnb.predict(test_data_features.toarray())#convert to dense array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data={\"file name\":testing_names,\"prediction\":result,\"label\":testing_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "correct = 0\n",
    "incorrect = []\n",
    "for i in range(100):\n",
    "    if output['prediction'][i] == output['label'][i]:\n",
    "        correct += 1\n",
    "        counter += 1\n",
    "    else:\n",
    "        incorrect.append(output['file name'][i])\n",
    "        counter += 1\n",
    "accuracy = correct/counter\n",
    "accuracy #got .67 with a Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
